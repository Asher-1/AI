# Using Deep Q-Network to Learn How To Play T-Rex Rush


## Getting Start

* Install dependencies `pip install -r requirements.txt`
* Run `python deep_q_network.py`

Notice: If you want to train on your own from scratch, comment [this line](deep_q_network.py#L108) and uncomment the line above. (Currently there is no pre-trained model)

## Dependencies

* Python 2.7 or 3
* Tensorflow >= 0.7
* pygame
* opencv-python

## About

This project is a tutorial demo for *hands-on tutorial on Deep Reinforcement Learning* at Xi'an Jiaotong-Liverpool University.

Details will be taught at class, but if you have a question, you are welcome to open an issue there.

## References

[1] Mnih Volodymyr, Koray Kavukcuoglu, David Silver, Andrei A. Rusu, Joel Veness, Marc G. Bellemare, Alex Graves, Martin Riedmiller, Andreas K. Fidjeland, Georg Ostrovski, Stig Petersen, Charles Beattie, Amir Sadik, Ioannis Antonoglou, Helen King, Dharshan Kumaran, Daan Wierstra, Shane Legg, and Demis Hassabis. **Human-level Control through Deep Reinforcement Learning.** Nature, 529-33, 2015.

[2] Junjie Ke, Yiwei Zhao, Honghao Wei. **AI For Chrome Offline Dinosaur Game** [Report](http://cs229.stanford.edu/proj2016/report/KeZhaoWei-AIForChromeOfflineDinosaurGame-report.pdf)


## Disclamier
This work is highly based on the following repos:
1. [yenchenlin/DeepLearningFlaapyBird](https://github.com/yenchenlin/DeepLearningFlappyBird)
2. [shivamshekhar/Chrome-T-Rex-Rush](https://github.com/shivamshekhar/Chrome-T-Rex-Rush)
