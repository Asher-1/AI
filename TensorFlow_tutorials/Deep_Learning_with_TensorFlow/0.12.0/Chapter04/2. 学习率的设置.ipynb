{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 假设我们要最小化函数  $y=x^2$, 选择初始点   $x_0=5$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. 学习率为1的时候，x在5和-5之间震荡。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After 1 iteration(s): x1 is -5.000000.\n",
      "After 2 iteration(s): x2 is 5.000000.\n",
      "After 3 iteration(s): x3 is -5.000000.\n",
      "After 4 iteration(s): x4 is 5.000000.\n",
      "After 5 iteration(s): x5 is -5.000000.\n",
      "After 6 iteration(s): x6 is 5.000000.\n",
      "After 7 iteration(s): x7 is -5.000000.\n",
      "After 8 iteration(s): x8 is 5.000000.\n",
      "After 9 iteration(s): x9 is -5.000000.\n",
      "After 10 iteration(s): x10 is 5.000000.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "TRAINING_STEPS = 10\n",
    "LEARNING_RATE = 1\n",
    "x = tf.Variable(tf.constant(5, dtype=tf.float32), name=\"x\")\n",
    "y = tf.square(x)\n",
    "\n",
    "train_op = tf.train.GradientDescentOptimizer(LEARNING_RATE).minimize(y)\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    for i in range(TRAINING_STEPS):\n",
    "        sess.run(train_op)\n",
    "        x_value = sess.run(x)\n",
    "        print \"After %s iteration(s): x%s is %f.\"% (i+1, i+1, x_value) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. 学习率为0.001的时候，下降速度过慢，在901轮时才收敛到0.823355。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After 1 iteration(s): x1 is 4.990000.\n",
      "After 101 iteration(s): x101 is 4.084646.\n",
      "After 201 iteration(s): x201 is 3.343555.\n",
      "After 301 iteration(s): x301 is 2.736923.\n",
      "After 401 iteration(s): x401 is 2.240355.\n",
      "After 501 iteration(s): x501 is 1.833880.\n",
      "After 601 iteration(s): x601 is 1.501153.\n",
      "After 701 iteration(s): x701 is 1.228794.\n",
      "After 801 iteration(s): x801 is 1.005850.\n",
      "After 901 iteration(s): x901 is 0.823355.\n"
     ]
    }
   ],
   "source": [
    "TRAINING_STEPS = 1000\n",
    "LEARNING_RATE = 0.001\n",
    "x = tf.Variable(tf.constant(5, dtype=tf.float32), name=\"x\")\n",
    "y = tf.square(x)\n",
    "\n",
    "train_op = tf.train.GradientDescentOptimizer(LEARNING_RATE).minimize(y)\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    for i in range(TRAINING_STEPS):\n",
    "        sess.run(train_op)\n",
    "        if i % 100 == 0: \n",
    "            x_value = sess.run(x)\n",
    "            print \"After %s iteration(s): x%s is %f.\"% (i+1, i+1, x_value)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "#### 3. 使用指数衰减的学习率，在迭代初期得到较高的下降速度，可以在较小的训练轮数下取得不错的收敛程度。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After 1 iteration(s): x1 is 4.000000, learning rate is 0.096000.\n",
      "After 11 iteration(s): x11 is 0.690561, learning rate is 0.063824.\n",
      "After 21 iteration(s): x21 is 0.222583, learning rate is 0.042432.\n",
      "After 31 iteration(s): x31 is 0.106405, learning rate is 0.028210.\n",
      "After 41 iteration(s): x41 is 0.065548, learning rate is 0.018755.\n",
      "After 51 iteration(s): x51 is 0.047625, learning rate is 0.012469.\n",
      "After 61 iteration(s): x61 is 0.038558, learning rate is 0.008290.\n",
      "After 71 iteration(s): x71 is 0.033523, learning rate is 0.005511.\n",
      "After 81 iteration(s): x81 is 0.030553, learning rate is 0.003664.\n",
      "After 91 iteration(s): x91 is 0.028727, learning rate is 0.002436.\n"
     ]
    }
   ],
   "source": [
    "TRAINING_STEPS = 100\n",
    "global_step = tf.Variable(0)\n",
    "LEARNING_RATE = tf.train.exponential_decay(0.1, global_step, 1, 0.96, staircase=True)\n",
    "\n",
    "x = tf.Variable(tf.constant(5, dtype=tf.float32), name=\"x\")\n",
    "y = tf.square(x)\n",
    "train_op = tf.train.GradientDescentOptimizer(LEARNING_RATE).minimize(y, global_step=global_step)\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    for i in range(TRAINING_STEPS):\n",
    "        sess.run(train_op)\n",
    "        if i % 10 == 0:\n",
    "            LEARNING_RATE_value = sess.run(LEARNING_RATE)\n",
    "            x_value = sess.run(x)\n",
    "            print \"After %s iteration(s): x%s is %f, learning rate is %f.\"% (i+1, i+1, x_value, LEARNING_RATE_value)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
