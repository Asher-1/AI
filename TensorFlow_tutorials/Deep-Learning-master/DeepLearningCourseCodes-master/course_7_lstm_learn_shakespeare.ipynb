{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hdf5 is not supported on this machine (please install/reinstall h5py for optimal experience)\n"
     ]
    }
   ],
   "source": [
    "from __future__ import absolute_import, division, print_function\n",
    "\n",
    "import os\n",
    "import pickle\n",
    "from six.moves import urllib\n",
    "\n",
    "import tflearn\n",
    "from tflearn.data_utils import *\n",
    "\n",
    "path = \"shakespeare_input.txt\"\n",
    "char_idx_file = 'char_idx.pickle'\n",
    "\n",
    "if not os.path.isfile(path):\n",
    "    urllib.request.urlretrieve(\"https://raw.githubusercontent.com/tflearn/tflearn.github.io/master/resources/shakespeare_input.txt\", path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading previous char_idx\n",
      "Vectorizing text...\n",
      "Text total length: 4,573,338\n",
      "Distinct chars   : 67\n",
      "Total sequences  : 1,524,438\n"
     ]
    }
   ],
   "source": [
    "maxlen = 25\n",
    "\n",
    "char_idx = None\n",
    "if os.path.isfile(char_idx_file):\n",
    "  print('Loading previous char_idx')\n",
    "  char_idx = pickle.load(open(char_idx_file, 'rb'))\n",
    "\n",
    "X, Y, char_idx = \\\n",
    "    textfile_to_semi_redundant_sequences(path, seq_maxlen=maxlen, redun_step=3,\n",
    "                                         pre_defined_char_idx=char_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pickle.dump(char_idx, open(char_idx_file,'wb'))\n",
    "\n",
    "g = tflearn.input_data([None, maxlen, len(char_idx)])\n",
    "g = tflearn.lstm(g, 512, return_seq=True)\n",
    "g = tflearn.dropout(g, 0.5)\n",
    "g = tflearn.lstm(g, 512, return_seq=True)\n",
    "g = tflearn.dropout(g, 0.5)\n",
    "g = tflearn.lstm(g, 512)\n",
    "g = tflearn.dropout(g, 0.5)\n",
    "g = tflearn.fully_connected(g, len(char_idx), activation='softmax')\n",
    "g = tflearn.regression(g, optimizer='adam', loss='categorical_crossentropy',\n",
    "                       learning_rate=0.001)\n",
    "\n",
    "m = tflearn.SequenceGenerator(g, dictionary=char_idx,\n",
    "                              seq_maxlen=maxlen,\n",
    "                              clip_gradients=5.0,\n",
    "                              checkpoint_path='model_shakespeare')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Step: 107189  | total loss: \u001b[1m\u001b[32m1.34488\u001b[0m\u001b[0m | time: 561.687s\n",
      "| Adam | epoch: 010 | loss: 1.34488 -- iter: 1371904/1371994\n",
      "Training Step: 107190  | total loss: \u001b[1m\u001b[32m1.35806\u001b[0m\u001b[0m | time: 600.688s\n",
      "| Adam | epoch: 010 | loss: 1.35806 | val_loss: 1.28005 -- iter: 1371994/1371994\n",
      "--\n",
      "INFO:tensorflow:/home/wei/Documents/DeepLearningCourseCodes/model_shakespeare-107190 is not in all_model_checkpoint_paths. Manually adding it.\n",
      "WARNING:tensorflow:Error encountered when serializing layer_tensor/LSTM.\n",
      "Type is unsupported, or the types of the items don't match field type in CollectionDef.\n",
      "'list' object has no attribute 'name'\n",
      "WARNING:tensorflow:Error encountered when serializing layer_tensor/Dropout.\n",
      "Type is unsupported, or the types of the items don't match field type in CollectionDef.\n",
      "'list' object has no attribute 'name'\n",
      "WARNING:tensorflow:Error encountered when serializing layer_tensor/LSTM_1.\n",
      "Type is unsupported, or the types of the items don't match field type in CollectionDef.\n",
      "'list' object has no attribute 'name'\n",
      "-- TESTING...\n",
      "-- Test with temperature of 1.0 --\n",
      "ou see'st with peril I have content, which reason'd let me clear?\n",
      "\n",
      "GORENIL:\n",
      "And what you have stop this occasion is better blame?\n",
      "\n",
      "PAROLLES:\n",
      "Why, with the enument in question not, peace, my father knight.\n",
      "I'll so know the night, being done,\n",
      "And villany, my doom, is the commanded tarteries.\n",
      "\n",
      "WARWICK:\n",
      "My son is thy place and quickly.\n",
      "How now, where wates, let Choefight and walks be bones;\n",
      "Our flock, if he have partled there than we\n",
      "enteral Mancanimone.\n",
      "\n",
      "PAGE:\n",
      "Carsing which not to seek it,\n",
      "Not yet worth and sow, beards of himself.\n",
      "\n",
      "POINS:\n",
      "All his cities, thou wilt there?\n",
      "\n",
      "DUGLET:\n",
      "My man for, goes but yet I do\n",
      "loathe, and\n",
      "-- Test with temperature of 0.5 --\n",
      "ou see'st with peril I have been to keep me to him.\n",
      "\n",
      "DON ADRIANO DE ARMADO:\n",
      "There is no fair course and honest sins\n",
      "And be the villain of the care of she is these death,\n",
      "And the speedy prince were so soon of the house.\n",
      "\n",
      "SIR TOBY BELCH:\n",
      "Thou shalt stand do the love of her soul,\n",
      "The last she will come a man to the rest,\n",
      "They so service and enemy.\n",
      "\n",
      "MARCIUS:\n",
      "I hope the name of France?\n",
      "\n",
      "FALSTAFF:\n",
      "Why, what is the father may have the large of a stand.\n",
      "\n",
      "DEMETRIUS:\n",
      "And I would not be my soul to him to him: and I have the love\n",
      "And be it in his fight.\n",
      "\n",
      "ALBANY:\n",
      "What was this to the heart;\n",
      "The night of the most prince and my most\n"
     ]
    }
   ],
   "source": [
    "for i in range(10):\n",
    "    seed = random_sequence_from_textfile(path, maxlen)\n",
    "    m.fit(X, Y, validation_set=0.1, batch_size=128,\n",
    "          n_epoch=1, run_id='shakespeare')\n",
    "    print(\"-- TESTING...\")\n",
    "    print(\"-- Test with temperature of 1.0 --\")\n",
    "    print(m.generate(600, temperature=1.0, seq_seed=seed))\n",
    "    print(\"-- Test with temperature of 0.5 --\")\n",
    "    print(m.generate(600, temperature=0.5, seq_seed=seed))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
